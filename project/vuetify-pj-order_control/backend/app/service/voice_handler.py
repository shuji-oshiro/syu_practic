import os
import whisper
import json
import wave
from openai import OpenAI
from dotenv import load_dotenv
from backend.app.service.fuzzy_matcher import fuzzy_menu_match

import sys
import queue
import sounddevice as sd
from vosk import Model, KaldiRecognizer

load_dotenv(dotenv_path="backend/.env")

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€whisper.load_model("base")ã‚’ä½¿ç”¨
model = whisper.load_model("base")


# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹é–¢æ•°
def transcribe_audiofile_on_localmodel(file_path: str):
    result = model.transcribe(file_path, language="ja")
    reco_text = result.get("text", "")
    
    if not isinstance(reco_text, str):
        raise TypeError("Whisper result['text'] is not a string")
    
    reco_text = reco_text.strip()
    return reco_text

# # OpenAI APIã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ã™ã‚‹é–¢æ•°
def transcribe_audiofile_on_APImodel(file_path: str):
    with open(file_path, "rb") as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file
        )
    reco_text = transcript.text.strip()
    return reco_text


# VOSKãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
base_dir = os.path.dirname(__file__)
model_path = os.path.join(base_dir, "models/vosk-model-small-ja-0.22")
model_vosk = Model(model_path)
   

def transcribe_audiofile_on_Vosk(file_path: str):

    # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
    try:
        wf = wave.open(file_path, "rb")
    except FileNotFoundError:
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(1)

    # WAVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚§ãƒƒã‚¯
    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:
        print("âš ï¸ WAVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãŒ VOSK ã«é©ã—ã¦ã„ã¾ã›ã‚“ï¼ˆå¿…è¦: mono/16bit/16kHzï¼‰")
        sys.exit(1)

    # menu_items = ["ã‹ã‚‰ã‚ã’", "ãƒ©ãƒ¼ãƒ¡ãƒ³", "ã‚«ãƒ¬ãƒ¼ãƒ©ã‚¤ã‚¹", "ã†ã©ã‚“"]
    # èªè­˜å™¨ã®åˆæœŸåŒ–
    recognizer = KaldiRecognizer(model_vosk, wf.getframerate())

    # éŸ³å£°èªè­˜
    print("ğŸ§ éŸ³å£°èªè­˜ã‚’é–‹å§‹...")
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if recognizer.AcceptWaveform(data):
            result = recognizer.Result()
            print("âœ… èªè­˜çµæœ:", result)

    # æœ€å¾Œã®éƒ¨åˆ†
    final_result = recognizer.FinalResult()
    return final_result