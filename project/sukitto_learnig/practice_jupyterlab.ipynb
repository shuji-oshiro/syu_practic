{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6badaa1-bede-4b26-9401-18d481cefc0f",
   "metadata": {},
   "source": [
    "#### basic_mind\n",
    "    superviskeyed learning（教師あり）: regression（回帰）classification（分類）\n",
    "        keyword: 特徴量、正解データ\n",
    "    unsupervised learning（教師なし）: clustering（クラスタリング）dimensionality reduction（次元削減）\n",
    "    \n",
    "#### 各関数：\n",
    "df[\"].value_counts() 1列分のデータ別個数の集計  \n",
    "df[\"].unique() 1列分のデータを重複を除いて抽出  \n",
    "df.dropna(how=\"all\" or \"any\", axis=0:row or 1:col)　None削除  \n",
    "df.drop(index or colname, axis= 0:row or 1:col) 行またはカラム名指定削除  \n",
    "df.loc[index, col] 特定の行列の抽出 :スライサOK  \n",
    "df[\"].fillna(\"replaceValue\")欠損値補完  \n",
    "df.loc[:,from_ColName:to_ColNmae] インデックス、カラム名指定取得 条件複数指定の場合   \n",
    "df_none = df[df.isnull().any(axis=1)] None行の取得  \n",
    "df_if = df[(df[a]>0) & (df[y]==\"val\")] 行の条件取得  \n",
    "\n",
    "df.shape　データフレームの全体概要出力  \n",
    "df.columns カラム名取得\n",
    "\n",
    "\n",
    "pd.concat([df_A, df_B], axis=0:addRow or 1:addCol, how=?)  \n",
    "pd.merge\n",
    "\n",
    "#### 描画\n",
    "df.plot(kind=\"scatter\", x=val, y=val) 散布図\n",
    "\n",
    "\n",
    "#### 機械学習\n",
    "pd.get_dummies(dataframe, drop_first=True) ダミーデータへ変換\n",
    "\n",
    "with open(\"fileName\",wb) as f; pickle.dump(\"saveModel\",f) モデル保存  \n",
    "with open(\"fileName\",rb) as f; pickle.load(\"saveModel\",f)　モデル読み込み\n",
    "\n",
    "標準化\n",
    "\n",
    "from sklearn.model_selection import train_test_split データの分割 複数可  \n",
    "x1,x2, y1,y2 = train_test_split(df_x, df_y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn import tree 決定木 分類 class_weightは任意  \n",
    "model = tree.DecisionTreeClassifier(max_depth=depth, random_state=0, class_weight=\"balanced\")  \n",
    "model.fit(x,y)  \n",
    "score = model.score(x=x_tr, y=y_tr)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression　回帰  \n",
    "model = LinearRegression()  \n",
    "model.fit(x,y) x:train y=corect  \n",
    "pred_value = model.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb264e-c576-4164-8a21-e12a6ec4f986",
   "metadata": {},
   "source": [
    "# 機械学習ラーニング　CHAPTER9　bank.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d83ce7-d90d-40cf-b067-45260bcf817d",
   "metadata": {},
   "source": [
    "## 文字列データのダミー化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425e2c78-867f-464a-b8c0-95a3b5d93079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sukkiri-ml2-codes/datafiles/bank.csv\")\n",
    "\n",
    "colname = [\"job\",\"marital\",\"education\",\"default\",\"housing\",\"loan\",\"contact\"] #文字情報が含まれる列\n",
    "df_str = df.loc[:,colname] #対象列のみ取得\n",
    "df_dummy = pd.get_dummies(df_str, drop_first=True) #文字情報のデータを数値化\n",
    "# Drop the original categorical columns from df\n",
    "df_without_cat = df.drop(colname, axis=1) #文字列情報が含まれる列を削除\n",
    "# Concatenate the numerical columns with dummy variables horizontally\n",
    "\n",
    "df_all = pd.concat([df, df_dummy], axis=1) #文字列、ダミーデータ含む全データ\n",
    "df2 = pd.concat([df_without_cat, df_dummy], axis=1)#文字列データをダミーデータ化した新しいＤＦ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2087d9ab-ccd2-4f17-b913-86fcd0e31583",
   "metadata": {},
   "source": [
    "## 訓練データとテストデータの分割、不要な項目を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32baf0b1-fc06-4d47-a6d8-e3eaf6ba9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df2 = df2.drop([\"id\",\"age\",\"amount\",\"day\",\"month\"],axis=1)#訓練データに関係のなさそうな列を削除\n",
    "train_val, test = train_test_split(df2,test_size=0.2,random_state=0)#訓練データとテストデータに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b8a7f-0a64-4e9c-9f7b-5f4a67b10516",
   "metadata": {},
   "source": [
    "## 機械学習による予測値の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f0ae73-da4c-4d9c-a5fe-a48c737e1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習による予測値\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# need to predict\n",
    "pred_x = train_val[train_val.isnull().any(axis=1)] #欠損値があるデータ\n",
    "pred_tr_val = train_val.dropna() #欠損値のない訓練データ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56df7b57-563d-4ed6-8e54-337fe8e8088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pred_tr_val.drop([\"duration\"],axis=1) #訓練データの列\n",
    "y = pred_tr_val[\"duration\"] #正解データの列\n",
    "model = LinearRegression()\n",
    "model.fit(x,y)#学習！！\n",
    "\n",
    "pred_x = pred_x.drop([\"duration\"],axis=1) #欠損値を予測するための検証データ\n",
    "pred_y = model.predict(pred_x)#予測値取得\n",
    "\n",
    "train_val.loc[train_val[\"duration\"].isnull(), \"duration\"] = pred_y#もとになる訓練データに欠損値を設定する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0202288-e744-489b-87bc-f8b6c4099999",
   "metadata": {},
   "source": [
    "## データの標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeff9a71-dcb6-4aab-a62f-6c381f7cb6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "深さ1：訓練スコア0.757 テストスコア0.756\n",
      "深さ2：訓練スコア0.757 テストスコア0.756\n",
      "深さ3：訓練スコア0.712 テストスコア0.706\n",
      "深さ4：訓練スコア0.753 テストスコア0.746\n",
      "深さ5：訓練スコア0.787 テストスコア0.779\n",
      "深さ6：訓練スコア0.781 テストスコア0.772\n",
      "深さ7：訓練スコア0.799 テストスコア0.788\n",
      "深さ8：訓練スコア0.812 テストスコア0.797\n",
      "深さ9：訓練スコア0.833 テストスコア0.801\n",
      "深さ10：訓練スコア0.842 テストスコア0.793\n",
      "深さ11：訓練スコア0.86 テストスコア0.795\n",
      "深さ12：訓練スコア0.871 テストスコア0.794\n",
      "深さ13：訓練スコア0.889 テストスコア0.795\n",
      "深さ14：訓練スコア0.901 テストスコア0.79\n",
      "実績スコア0.719\n"
     ]
    }
   ],
   "source": [
    "## 性能テスト\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def learn(x,t,depth=1): # 訓練データと検証データのスコアを返す処理\n",
    "    x_tr, x_test, y_tr, y_test = train_test_split(x, t, test_size=0.2, random_state=0)\n",
    "\n",
    "    # 課題・・・・・・・・・・・・・・・・・・・・・・・・・・・・・・\n",
    "    # 訓練データの標準化\n",
    "    sc_model_x = StandardScaler()\n",
    "    sc_model_y = StandardScaler()\n",
    "    sc_model_x.fit(x_tr) #標準化する前準備\n",
    "    sc_model_y.fit(y_tr)\n",
    "    \n",
    "    sc_x_tr = sc_model_x.transform(x_tr)#データの標準化処理\n",
    "    sc_y_tr = sc_model_y.transform(y_tr)\n",
    "\n",
    "    # x_tr = sc_model_x.inverse_tranceform(sc_x_tr)#標準化されたデータをもとに戻す処理　predictなどで予測値を取得する際はもとに戻す必要あり　\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier(max_depth=depth, random_state=0, class_weight=\"balanced\")\n",
    "    # model = tree.DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
    "    model.fit(x_tr, y_tr)#学習モデルの訓練データは標準化されたデータで学習されていることに注意\n",
    "    \n",
    "    # 検証データの標準化\n",
    "    sc_x_val = sc_model_x.transform(x_test)#データの標準化処理\n",
    "    sc_y_val = sc_model_y.transform(y_test)\n",
    "\n",
    "    score = model.score(x_tr, y_tr)#訓練データのスコア\n",
    "    score2 = model.score(x_test, y_test)#検証データのスコア\n",
    "    return round(score,3), round(score2,3), model\n",
    "\n",
    "x = train_val.drop(\"y\",axis=1)\n",
    "t = train_val[[\"y\"]]\n",
    "\n",
    "for i in range(1,15):\n",
    "    tr_score, test_score, model = learn(x, t, i)\n",
    "    print(f\"深さ{i}：訓練スコア{tr_score} テストスコア{test_score}\")\n",
    "\n",
    "# 性能が高いモデルでテスト\n",
    "tr_score, test_score, model = learn(x, t, 8)\n",
    "_test = test.dropna()\n",
    "x = _test.drop(\"y\",axis=1)\n",
    "y = _test[\"y\"]\n",
    "\n",
    "score = model.score(x, y)\n",
    "print(f\"実績スコア{round(score,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d266c70-cd9b-40a6-a7cd-d68d710311df",
   "metadata": {},
   "source": [
    "## マハラノビスによる外れ値の除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "980f6ff1-609c-42f3-9d60-3c2161c3b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import MinCovDet\n",
    "mcd = MinCovDet(random_state=0, support_fraction=0.7)\n",
    "\n",
    "train_val = train_val.reset_index()\n",
    "mcd.fit(train_val)#マハラノビス距離を計算するために必要な共分散行列を計算\n",
    "\n",
    "#!!point!! 元データを使って距離を計測しているがシリーズに変換した際、indexが再度採番されていることに注意\n",
    "#対象方法としては、元データのインデックスリセットするなどの処理が必要\n",
    "distance = mcd.mahalanobis(train_val) #距離測定\n",
    "s_distance = pd.Series(distance)#describe関数を使用するためにシリーズに変換\n",
    "\n",
    "tmp=s_distance.describe()\n",
    "\n",
    "iqr = tmp[\"75%\"] - tmp[\"25%\"] #ＩＱＲ＝四分位範囲＝第3四分位数（75％）－第1四分位（25％）\n",
    "maxval = (iqr*1.5) + tmp[\"75%\"]#上限値のしきい値=第3四分位数＋（1.5*75％）\n",
    "minval = tmp[\"25%\"] - (iqr*1.5)#下限値のしきい値=第1四分位数－（1.5*75％）\n",
    "\n",
    "clear_data = s_distance[(s_distance > maxval) | (minval > s_distance)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abc397e5-dc01-42a2-ae01-2c6187038e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val (21702, 26)\n",
      "s_distance (21702,)\n",
      "clear_data (2620,)\n",
      "train_val_without_mahalanobis (19082, 26)\n"
     ]
    }
   ],
   "source": [
    "train_val_without_mahalanobis = train_val.drop(clear_data.index)\n",
    "print(\"train_val\",train_val.shape)\n",
    "print(\"s_distance\",s_distance.shape)\n",
    "print(\"clear_data\",clear_data.shape)\n",
    "print(\"train_val_without_mahalanobis\",train_val2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "999191d3-ce38-431b-9c9e-3adbf599660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相関係数（上位10項目）:\n",
      "duration                     0.453555\n",
      "housing_yes                  0.197832\n",
      "campaign                     0.146778\n",
      "contact_sending _document    0.131849\n",
      "loan_yes                     0.096758\n",
      "marital_single               0.066403\n",
      "marital_married              0.055259\n",
      "job_student                  0.051178\n",
      "job_blue-collar              0.039722\n",
      "job_unemployed               0.030056\n",
      "Name: y, dtype: float64\n",
      "相関係数（上位10項目）:\n",
      "duration                     0.458181\n",
      "housing_yes                  0.209083\n",
      "campaign                     0.192961\n",
      "contact_sending _document    0.152239\n",
      "loan_yes                     0.107319\n",
      "marital_single               0.068297\n",
      "marital_married              0.055134\n",
      "job_student                  0.054618\n",
      "job_blue-collar              0.045171\n",
      "education_tertiary           0.030686\n",
      "Name: y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. 相関係数を計算\n",
    "# yと他の特徴量との相関係数を計算し、絶対値で降順にソート\n",
    "correlations = train_val.corr()['y'].abs().sort_values(ascending=False)\n",
    "print(\"相関係数（上位10項目）:\")\n",
    "print(correlations[1:11])  # yとの相関を除いて上位10項目を表示\n",
    "\n",
    "\n",
    "# # 相関係数上位5項目についてボックスプロットを作成\n",
    "# top_features = correlations[1:6].index\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "# axes = axes.ravel()\n",
    "\n",
    "# for idx, feature in enumerate(top_features):\n",
    "#     sns.boxplot(data=train_val, x='y', y=feature, ax=axes[idx])\n",
    "#     axes[idx].set_title(f'{feature} vs y')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4c2d9-9d81-4933-ba1c-ce4e92138a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecfbc87-3f6f-46d7-aeda-c7adbdfc263a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
